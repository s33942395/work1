import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import warnings
import os
import re

st.set_page_config(layout="wide", page_title="å•å·äº’å‹•åˆ†æå ±å‘Š")

@st.cache_data
def load_and_concat(file_paths):
    all_dfs = []
    for path in file_paths:
        try:
            df = pd.read_csv(path)
            df.columns = df.columns.str.replace(r'ã€.*?ã€‘', '', regex=True).str.strip()
            df.columns = df.columns.str.replace('\n', ' ', regex=False)

            # è‹¥ CSV å·²æœ‰éšæ®µæ¬„ä½ï¼Œå°‡åƒ "ç¬¬ä¸€éšæ®µï¼š..."ã€"ç¬¬ä¸€éšæ®µï¼..." ç­‰å€¼æ­£è¦åŒ–ç‚º "ç¬¬ä¸€éšæ®µ"
            if PHASE_COLUMN_NAME in df.columns:
                extracted = df[PHASE_COLUMN_NAME].astype(str).str.extract(r'(ç¬¬ä¸€éšæ®µ|ç¬¬äºŒéšæ®µ|ç¬¬ä¸‰éšæ®µ)', expand=False)
                # è‹¥èƒ½æŠ½å‡ºæ¨™æº–éšæ®µåç¨±ï¼Œä½¿ç”¨å®ƒï¼›å¦å‰‡ä¿ç•™åŸå€¼ï¼ˆé¿å…ç ´å£éé æœŸæ ¼å¼ï¼‰
                df[PHASE_COLUMN_NAME] = extracted.where(extracted.notna(), df[PHASE_COLUMN_NAME])
            else:
                # å¦‚æœ CSV æœ¬èº«æ²’æœ‰éšæ®µæ¬„ä½ï¼Œå˜—è©¦å¾æª”åæ¨æ–·ï¼ˆç¬¬ä¸€éšæ®µ / ç¬¬äºŒéšæ®µ / ç¬¬ä¸‰éšæ®µï¼‰
                m = re.search(r'(ç¬¬ä¸€éšæ®µ|ç¬¬äºŒéšæ®µ|ç¬¬ä¸‰éšæ®µ)', os.path.basename(path))
                if m:
                    df[PHASE_COLUMN_NAME] = m.group(1)

            # åŠ å…¥ä¾†æºæª”åä»¥ä¾¿è¿½è¹¤ä¾†æº
            df['_source_file'] = os.path.basename(path)

            all_dfs.append(df)
        except FileNotFoundError:
            st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ {path}ã€‚è«‹ç¢ºèªæ‰€æœ‰ CSV æª”æ¡ˆéƒ½å·²å’Œ app è…³æœ¬ä¸€åŒä¸Šå‚³è‡³ GitHubã€‚")
            return None
    if not all_dfs: return pd.DataFrame()
    return pd.concat(all_dfs, ignore_index=True, sort=False)

st.title("ğŸ“Š å•å·è³‡æ–™äº’å‹•åˆ†æå ±å‘Š (é›²ç«¯ç‰ˆ)")
st.markdown("è«‹å…ˆé¸æ“‡åˆ†ææ¨¡å¼ï¼Œç„¶å¾Œå†æ ¹æ“šæç¤ºé¸æ“‡è¦æŸ¥çœ‹çš„è³‡æ–™ç¯„åœã€‚")

# --- File Definitions (Relative Paths for Cloud) ---
COMPANY_P1_FILE = "STANDARD_8RG8Y_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸€éšæ®µ_202511050604_690ae8db08878.csv"
COMPANY_P2_FILE = "STANDARD_7RGxP_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬äºŒéšæ®µ_202511050605_690ae92a9a127.csv"
COMPANY_P3_FILE = "STANDARD_Yb9D2_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸‰éšæ®µ_202511050605_690ae9445a228.csv"
INVESTOR_P1_FILE = "STANDARD_NwNYM_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸€éšæ®µæŠ•è³‡æ–¹_202511060133_690bfaccec28e.csv"
INVESTOR_P2_FILE = "STANDARD_v2xYO_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬äºŒéšæ®µæŠ•è³‡æ–¹_202511060133_690bfae9b9065.csv"
INVESTOR_P3_FILE = "STANDARD_we89e_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸‰éšæ®µæŠ•è³‡æ–¹_202511060133_690bfb0524491.csv"
COMPANY_NEW_MULTIPHASE_FILE = "STANDARD_v2xkX_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·_202511060532_690c3305c62b5.csv"
PHASE_COLUMN_NAME = "è«‹å•å…¬å¸ç›®å‰ä¸»è¦è™•æ–¼å“ªå€‹ç™¼å±•éšæ®µï¼Ÿï¼š"

company_files = {"ç¬¬ä¸€éšæ®µ": COMPANY_P1_FILE, "ç¬¬äºŒéšæ®µ": COMPANY_P2_FILE, "ç¬¬ä¸‰éšæ®µ": COMPANY_P3_FILE}
investor_files = {"ç¬¬ä¸€éšæ®µ": INVESTOR_P1_FILE, "ç¬¬äºŒéšæ®µ": INVESTOR_P2_FILE, "ç¬¬ä¸‰éšæ®µ": INVESTOR_P3_FILE}

# --- UI Logic ---
analysis_mode = st.radio("**æ­¥é©Ÿä¸€ï¼šè«‹é¸æ“‡åˆ†ææ¨¡å¼**", ('é€é¡Œç€è¦½', 'åˆä½µåˆ†æ'), horizontal=True, key="main_mode")

df_to_analyze = pd.DataFrame()
report_title = ""

try:
    df_new_multi = load_and_concat([COMPANY_NEW_MULTIPHASE_FILE])
except Exception:
    df_new_multi = pd.DataFrame()

if analysis_mode == 'é€é¡Œç€è¦½':
    data_side = st.radio("**æ­¥é©ŸäºŒï¼šè«‹é¸æ“‡è¦åˆ†æçš„å°è±¡**", ('å…¬å¸æ–¹', 'æŠ•è³‡æ–¹'), horizontal=True, key='data_side_selector')
    phase_options = list(company_files.keys()) + ["ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)"]
    selected_phase = st.selectbox("**æ­¥é©Ÿä¸‰ï¼šè«‹é¸æ“‡å•å·éšæ®µ**", phase_options, key='phase_selector_separate')
    report_title = f"{data_side} - {selected_phase}"
    df_list = []
    if data_side == 'å…¬å¸æ–¹':
        files_to_load = []
        if selected_phase in company_files: files_to_load.append(company_files[selected_phase])
        elif selected_phase == "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)": files_to_load.extend(list(company_files.values()))
        if files_to_load: df_list.append(load_and_concat(files_to_load))
        if df_new_multi is not None and not df_new_multi.empty:
            if selected_phase in company_files: 
                df_filtered = df_new_multi[df_new_multi[PHASE_COLUMN_NAME].str.contains(selected_phase, na=False)]
                df_list.append(df_filtered)
            elif selected_phase == "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)": df_list.append(df_new_multi)
    else: # Investor side
        files_to_load = []
        if selected_phase in investor_files: files_to_load.append(investor_files[selected_phase])
        else: files_to_load = list(investor_files.values())
        if files_to_load: df_list.append(load_and_concat(files_to_load))
    if df_list: df_to_analyze = pd.concat(df_list, ignore_index=True, sort=False)

else: # Merged Analysis
    merge_option = st.selectbox("**æ­¥é©ŸäºŒï¼šè«‹é¸æ“‡åˆä½µç¯„åœ**", ("ç¬¬ä¸€éšæ®µ (åˆä½µ)", "ç¬¬äºŒéšæ®µ (åˆä½µ)", "ç¬¬ä¸‰éšæ®µ (åˆä½µ)", "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)"), key='phase_selector_merged')
    report_title = merge_option
    files_to_load = []
    phase_filter = None
    if merge_option == "ç¬¬ä¸€éšæ®µ (åˆä½µ)": files_to_load, phase_filter = [COMPANY_P1_FILE, INVESTOR_P1_FILE], "ç¬¬ä¸€éšæ®µ"
    elif merge_option == "ç¬¬äºŒéšæ®µ (åˆä½µ)": files_to_load, phase_filter = [COMPANY_P2_FILE, INVESTOR_P2_FILE], "ç¬¬äºŒéšæ®µ"
    elif merge_option == "ç¬¬ä¸‰éšæ®µ (åˆä½µ)": files_to_load = [COMPANY_P3_FILE, INVESTOR_P3_FILE]
    else: files_to_load = list(company_files.values()) + list(investor_files.values()) + [COMPANY_NEW_MULTIPHASE_FILE]
    df_base = load_and_concat(files_to_load)
    df_list = [df_base]
    if phase_filter and df_new_multi is not None and not df_new_multi.empty:
        df_filtered = df_new_multi[df_new_multi[PHASE_COLUMN_NAME].str.contains(phase_filter, na=False)]
        df_list.append(df_filtered)
    if df_list: df_to_analyze = pd.concat(df_list, ignore_index=True, sort=False)

# --- Display Analysis ---
st.header(f"æ‚¨æ­£åœ¨æŸ¥çœ‹ï¼š{report_title}çš„åˆ†æçµæœ")
if df_to_analyze is not None and not df_to_analyze.empty:
    st.metric(label="ç¸½æ¨£æœ¬æ•¸ (å•å·ä»½æ•¸)", value=len(df_to_analyze))
    st.markdown("---")
    expand_all = st.checkbox("ä¸€éµå±•é–‹/æ”¶åˆæ‰€æœ‰é¡Œç›®", value=False, key="expand_all_toggle")
    st.markdown("---")
    cols_to_exclude = ['ç‚ºäº†å¾ŒçºŒæ”¯ä»˜è¨ªè«‡è²»ï¼Œè«‹æä¾›æ‚¨çš„é›»å­éƒµä»¶åœ°å€ï¼ˆæˆ‘å€‘å°‡åƒ…ç”¨æ–¼è¯ç¹«æ‚¨æ”¯ä»˜è¨ªè«‡è²»ï¼Œä¸¦å¦¥å–„ä¿è­·æ‚¨çš„è³‡æ–™ï¼‰:', 'IPç´€éŒ„', 'é¡æ»¿çµæŸè¨»è¨˜', 'ä½¿ç”¨è€…ç´€éŒ„', 'æœƒå“¡æ™‚é–“', 'Hash', 'æœƒå“¡ç·¨è™Ÿ', 'è‡ªè¨‚ID', 'å‚™è¨»', 'å¡«ç­”æ™‚é–“', PHASE_COLUMN_NAME]
    analysis_cols = [col for col in df_to_analyze.columns if col not in cols_to_exclude and col in df_to_analyze.columns]
    analysis_cols = list(pd.Series(analysis_cols))
    for i, col_name in enumerate(analysis_cols):
        col_data = df_to_analyze[col_name].dropna()
        if not col_data.empty:
            with st.expander(f"é¡Œç›®ï¼š{col_name}", expanded=expand_all):
                is_multiselect = False
                if col_data.dtype == 'object':
                    non_empty_data = col_data[col_data.astype(str) != '']
                    if not non_empty_data.empty and non_empty_data.str.contains('\n').any(): is_multiselect = True
                if is_multiselect:
                    st.markdown("##### è¤‡é¸é¡Œé¸é …æ¬¡æ•¸åˆ†ä½ˆ")
                    exploded = col_data.astype(str).str.split('\n').explode().str.strip()
                    exploded = exploded[exploded != '']
                    total_counts = exploded.value_counts().reset_index()
                    total_counts.columns = ['ç¨ç«‹é¸é …', 'æ¬¡æ•¸']
                    st.dataframe(total_counts)

                    # è‹¥è³‡æ–™å«éšæ®µæ¬„ä½ä¸”æœ‰å¤šå€‹éšæ®µï¼Œå‰‡æŒ‰éšæ®µåˆ†è‰²ï¼ˆå †ç–Šï¼‰
                    if PHASE_COLUMN_NAME in df_to_analyze.columns and df_to_analyze[PHASE_COLUMN_NAME].notna().any() and df_to_analyze[PHASE_COLUMN_NAME].nunique() > 1:
                        st.markdown("##### å„éšæ®µåˆ†ä½ˆï¼ˆä¸åŒé¡è‰²ä»£è¡¨ä¸åŒéšæ®µï¼Œæ¡å †ç–Šé¡¯ç¤ºï¼‰")
                        exploded_df = exploded.to_frame(name='option')
                        exploded_df['phase'] = df_to_analyze.loc[exploded_df.index, PHASE_COLUMN_NAME].fillna('æœªæ¨™è¨»éšæ®µ')
                        pivot = exploded_df.groupby(['option', 'phase']).size().unstack(fill_value=0)
                        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
                        fig = go.Figure()
                        for j, phase in enumerate(pivot.columns):
                            fig.add_trace(go.Bar(x=pivot.index, y=pivot[phase], name=str(phase), marker_color=colors[j % len(colors)]))
                        fig.update_layout(barmode='stack', xaxis_tickangle=0, template="plotly_white")
                        st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_multi")
                    else:
                        st.markdown("##### å‚ç›´é•·æ¢åœ–")
                        fig = go.Figure(data=[go.Bar(x=total_counts['ç¨ç«‹é¸é …'], y=total_counts['æ¬¡æ•¸'])])
                        fig.update_layout(xaxis_tickangle=0, template="plotly_white")
                        st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_multi")
                else:
                    is_numeric = pd.api.types.is_numeric_dtype(col_data)
                    if not is_numeric:
                        numeric_version = pd.to_numeric(col_data, errors='coerce');
                        if (numeric_version.notna().sum() / len(col_data) > 0.7): is_numeric = True; col_data = numeric_version.dropna()
                    if is_numeric:
                        st.markdown("##### æ•¸å€¼å‹è³‡æ–™çµ±è¨ˆæ‘˜è¦"); st.dataframe(col_data.describe().to_frame().T.style.format("{:,.2f}")); st.markdown("##### ç›’ç‹€åœ–"); fig = go.Figure(data=[go.Box(y=col_data, name=col_name)]); fig.update_layout(xaxis_tickangle=0, template="plotly_white"); st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_num")
                    else:
                        st.markdown("##### é¡åˆ¥å‹è³‡æ–™æ¬¡æ•¸åˆ†ä½ˆ")
                        s = col_data.astype(str)
                        total = s.value_counts().reset_index()
                        total.columns = ['ç­”æ¡ˆé¸é …', 'æ¬¡æ•¸']
                        st.dataframe(total)

                        # è‹¥è³‡æ–™å«éšæ®µæ¬„ä½ä¸”æœ‰å¤šå€‹éšæ®µï¼Œå‰‡æŒ‰éšæ®µåˆ†è‰²ï¼ˆå †ç–Šï¼‰
                        if PHASE_COLUMN_NAME in df_to_analyze.columns and df_to_analyze[PHASE_COLUMN_NAME].notna().any() and df_to_analyze[PHASE_COLUMN_NAME].nunique() > 1:
                            st.markdown("##### å„éšæ®µåˆ†ä½ˆï¼ˆä¸åŒé¡è‰²ä»£è¡¨ä¸åŒéšæ®µï¼Œæ¡å †ç–Šé¡¯ç¤ºï¼‰")
                            df_pair = s.to_frame(name='ans')
                            df_pair['phase'] = df_to_analyze.loc[df_pair.index, PHASE_COLUMN_NAME].fillna('æœªæ¨™è¨»éšæ®µ')
                            pivot = df_pair.groupby(['ans', 'phase']).size().unstack(fill_value=0)
                            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
                            fig = go.Figure()
                            for j, phase in enumerate(pivot.columns):
                                fig.add_trace(go.Bar(x=pivot.index, y=pivot[phase], name=str(phase), marker_color=colors[j % len(colors)]))
                            fig.update_layout(barmode='stack', xaxis_tickangle=0, template="plotly_white")
                            st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_cat")
                        else:
                            st.markdown("##### å‚ç›´é•·æ¢åœ–")
                            fig = go.Figure(data=[go.Bar(x=total['ç­”æ¡ˆé¸é …'], y=total['æ¬¡æ•¸'])])
                            fig.update_layout(xaxis_tickangle=0, template="plotly_white")
                            st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_cat")
else: st.warning("åœ¨æ­¤é¸æ“‡ä¸‹æ²’æœ‰è¼‰å…¥ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œæª”æ¡ˆã€‚")