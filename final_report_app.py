
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go

st.set_page_config(layout="wide", page_title="å•å·äº’å‹•åˆ†æå ±å‘Š")

@st.cache_data
def load_and_concat(file_paths):
    """Loads, cleans column names, and concatenates data from a list of file paths."""
    all_dfs = []
    for path in file_paths:
        try:
            df = pd.read_csv(path)
            # Normalize column names by removing prefixes like ã€...ã€‘ and stripping whitespace
            df.columns = df.columns.str.replace(r'ã€.*?ã€‘', '', regex=True).str.strip()
            df.columns = df.columns.str.replace('\n', ' ', regex=False)
            all_dfs.append(df)
        except FileNotFoundError:
            st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ {path}ã€‚è«‹ç¢ºèªæ‰€æœ‰ CSV æª”æ¡ˆéƒ½å·²å’Œ app è…³æœ¬ä¸€åŒä¸Šå‚³è‡³ GitHubã€‚")
            return None
    
    if not all_dfs:
        return pd.DataFrame()

    merged_df = pd.concat(all_dfs, ignore_index=True, sort=False)
    return merged_df

# --- App Header and File Definitions ---
st.title("ğŸ“Š å•å·è³‡æ–™äº’å‹•åˆ†æå ±å‘Š")
st.markdown("è«‹å…ˆé¸æ“‡åˆ†ææ¨¡å¼ï¼Œç„¶å¾Œå†æ ¹æ“šæç¤ºé¸æ“‡è¦æŸ¥çœ‹çš„è³‡æ–™ç¯„åœã€‚")

# --- Use RELATIVE paths for deployment ---
COMPANY_P1_FILE = "STANDARD_8RG8Y_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸€éšæ®µ_202511050604_690ae8db08878.csv"
COMPANY_P2_FILE = "STANDARD_7RGxP_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬äºŒéšæ®µ_202511050605_690ae92a9a127.csv"
COMPANY_P3_FILE = "STANDARD_Yb9D2_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸‰éšæ®µ_202511050605_690ae9445a228.csv"
INVESTOR_P1_FILE = "STANDARD_NwNYM_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸€éšæ®µæŠ•è³‡æ–¹_202511060133_690bfaccec28e.csv"
INVESTOR_P2_FILE = "STANDARD_v2xYO_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬äºŒéšæ®µæŠ•è³‡æ–¹_202511060133_690bfae9b9065.csv"
INVESTOR_P3_FILE = "STANDARD_we89e_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·ç¬¬ä¸‰éšæ®µæŠ•è³‡æ–¹_202511060133_690bfb0524491.csv"
COMPANY_NEW_MULTIPHASE_FILE = "STANDARD_v2xkX_æœªä¸Šå¸‚æ«ƒå…¬å¸æ²»ç†å•å·_202511060532_690c3305c62b5.csv"
PHASE_COLUMN_NAME = "è«‹å•å…¬å¸ç›®å‰ä¸»è¦è™•æ–¼å“ªå€‹ç™¼å±•éšæ®µï¼Ÿï¼š"

company_files = {"ç¬¬ä¸€éšæ®µ": COMPANY_P1_FILE, "ç¬¬äºŒéšæ®µ": COMPANY_P2_FILE, "ç¬¬ä¸‰éšæ®µ": COMPANY_P3_FILE}
investor_files = {"ç¬¬ä¸€éšæ®µ": INVESTOR_P1_FILE, "ç¬¬äºŒéšæ®µ": INVESTOR_P2_FILE, "ç¬¬ä¸‰éšæ®µ": INVESTOR_P3_FILE}

# --- UI Logic ---
analysis_mode = st.radio("**æ­¥é©Ÿä¸€ï¼šè«‹é¸æ“‡åˆ†ææ¨¡å¼**", ('åˆ†é–‹æ¯”è¼ƒ', 'åˆä½µåˆ†æ'), horizontal=True)

report_title = ""
df_to_analyze = pd.DataFrame()

# We need to load the new multi-phase file to filter it, so load it once here.
try:
    df_new_multi = load_and_concat([COMPANY_NEW_MULTIPHASE_FILE])
except Exception as e:
    # This will be caught by the load_and_concat function, but as a fallback:
    st.error(f"ç„¡æ³•è®€å–æ–°çš„å…¬å¸æ–¹å•å·æª”æ¡ˆ: {COMPANY_NEW_MULTIPHASE_FILE}ã€‚è«‹ç¢ºèªæ­¤æª”æ¡ˆå·²ä¸Šå‚³ã€‚")
    df_new_multi = pd.DataFrame()

if analysis_mode == 'åˆ†é–‹æ¯”è¼ƒ':
    data_side = st.radio("**æ­¥é©ŸäºŒï¼šè«‹é¸æ“‡è¦åˆ†æçš„å°è±¡**", ('å…¬å¸æ–¹', 'æŠ•è³‡æ–¹'), horizontal=True, key='data_side_selector')
    phase_options = list(company_files.keys()) + ["ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)"]
    selected_phase = st.selectbox("**æ­¥é©Ÿä¸‰ï¼šè«‹é¸æ“‡å•å·éšæ®µ**", phase_options, key='phase_selector_separate')
    report_title = f"{data_side} - {selected_phase}"

    df_list = []
    if data_side == 'å…¬å¸æ–¹':
        files_to_load = []
        if selected_phase in company_files:
            files_to_load.append(company_files[selected_phase])
        elif selected_phase == "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)":
            files_to_load.extend(list(company_files.values()))
        
        if files_to_load: df_list.append(load_and_concat(files_to_load))

        if df_new_multi is not None and not df_new_multi.empty:
            if selected_phase in company_files:
                df_filtered = df_new_multi[df_new_multi[PHASE_COLUMN_NAME].str.contains(selected_phase, na=False)]
                df_list.append(df_filtered)
            elif selected_phase == "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)":
                df_list.append(df_new_multi)
    else: # Investor side
        files_to_load = []
        if selected_phase in investor_files:
            files_to_load.append(investor_files[selected_phase])
        else: 
            files_to_load = list(investor_files.values())
        if files_to_load: df_list.append(load_and_concat(files_to_load))
    
    if df_list: df_to_analyze = pd.concat(df_list, ignore_index=True, sort=False)

else: # Merged Analysis
    merge_option = st.selectbox("**æ­¥é©ŸäºŒï¼šè«‹é¸æ“‡åˆä½µç¯„åœ**", ("ç¬¬ä¸€éšæ®µ (åˆä½µ)", "ç¬¬äºŒéšæ®µ (åˆä½µ)", "ç¬¬ä¸‰éšæ®µ (åˆä½µ)", "ä¸åˆ†éšæ®µ (å…¨éƒ¨åˆä½µ)"), key='phase_selector_merged')
    report_title = merge_option
    files_to_load = []
    phase_filter = None

    if merge_option == "ç¬¬ä¸€éšæ®µ (åˆä½µ)":
        files_to_load = [COMPANY_P1_FILE, INVESTOR_P1_FILE]
        phase_filter = "ç¬¬ä¸€éšæ®µ"
    elif merge_option == "ç¬¬äºŒéšæ®µ (åˆä½µ)":
        files_to_load = [COMPANY_P2_FILE, INVESTOR_P2_FILE]
        phase_filter = "ç¬¬äºŒéšæ®µ"
    elif merge_option == "ç¬¬ä¸‰éšæ®µ (åˆä½µ)":
        files_to_load = [COMPANY_P3_FILE, INVESTOR_P3_FILE]
    else: # All
        files_to_load = list(company_files.values()) + list(investor_files.values()) + [COMPANY_NEW_MULTIPHASE_FILE]

    df_base = load_and_concat(files_to_load)
    df_list = [df_base]
    if phase_filter and df_new_multi is not None and not df_new_multi.empty:
        df_filtered = df_new_multi[df_new_multi[PHASE_COLUMN_NAME].str.contains(phase_filter, na=False)]
        df_list.append(df_filtered)
    
    if df_list: df_to_analyze = pd.concat(df_list, ignore_index=True, sort=False)

# --- Display Analysis ---
st.header(f"æ‚¨æ­£åœ¨æŸ¥çœ‹ï¼š{report_title}çš„åˆ†æçµæœ")
if df_to_analyze is not None and not df_to_analyze.empty:
    st.metric(label="ç¸½æ¨£æœ¬æ•¸ (å•å·ä»½æ•¸)", value=len(df_to_analyze))
    st.markdown("---")
    expand_all = st.checkbox("ä¸€éµå±•é–‹/æ”¶åˆæ‰€æœ‰é¡Œç›®", value=False, key="expand_all_toggle")
    st.markdown("---")

    cols_to_exclude = ['ç‚ºäº†å¾ŒçºŒæ”¯ä»˜è¨ªè«‡è²»ï¼Œè«‹æä¾›æ‚¨çš„é›»å­éƒµä»¶åœ°å€ï¼ˆæˆ‘å€‘å°‡åƒ…ç”¨æ–¼è¯ç¹«æ‚¨æ”¯ä»˜è¨ªè«‡è²»ï¼Œä¸¦å¦¥å–„ä¿è­·æ‚¨çš„è³‡æ–™ï¼‰:', 'IPç´€éŒ„', 'é¡æ»¿çµæŸè¨»è¨˜', 'ä½¿ç”¨è€…ç´€éŒ„', 'æœƒå“¡æ™‚é–“', 'Hash', 'æœƒå“¡ç·¨è™Ÿ', 'è‡ªè¨‚ID', 'å‚™è¨»', 'å¡«ç­”æ™‚é–“', PHASE_COLUMN_NAME]
    analysis_cols = [col for col in df_to_analyze.columns if col not in cols_to_exclude and col in df_to_analyze.columns]
    analysis_cols = list(pd.Series(analysis_cols)) # Get unique columns while preserving order

    for i, col_name in enumerate(analysis_cols):
        with st.expander(f"é¡Œç›®ï¼š{col_name}", expanded=expand_all):
            col_data = df_to_analyze[col_name].dropna()
            if col_data.empty: st.warning("æ­¤æ¬„ä½ç„¡æœ‰æ•ˆè³‡æ–™å¯ä¾›åˆ†æã€‚"); continue
            is_multiselect = False
            if col_data.dtype == 'object':
                non_empty_data = col_data[col_data.astype(str) != '']
                if not non_empty_data.empty and non_empty_data.str.contains('\n').any(): is_multiselect = True
            if is_multiselect:
                st.markdown("##### è¤‡é¸é¡Œé¸é …æ¬¡æ•¸åˆ†ä½ˆ"); exploded_data = col_data.str.split('\n').explode().str.strip(); exploded_data = exploded_data[exploded_data != '']; stats_df = exploded_data.value_counts().reset_index(); stats_df.columns = ['ç¨ç«‹é¸é …', 'æ¬¡æ•¸']; st.dataframe(stats_df)
                st.markdown("##### å‚ç›´é•·æ¢åœ–"); fig = go.Figure(data=[go.Bar(x=stats_df['ç¨ç«‹é¸é …'], y=stats_df['æ¬¡æ•¸'])]); fig.update_layout(xaxis_tickangle=0, template="plotly_white"); st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_multi")
            else:
                is_numeric = pd.api.types.is_numeric_dtype(col_data)
                if not is_numeric:
                    numeric_version = pd.to_numeric(col_data, errors='coerce');
                    if (numeric_version.notna().sum() / len(col_data) > 0.7): is_numeric = True; col_data = numeric_version.dropna()
                if is_numeric:
                    st.markdown("##### æ•¸å€¼å‹è³‡æ–™çµ±è¨ˆæ‘˜è¦"); st.dataframe(col_data.describe().to_frame().T.style.format("{:,.2f}")); st.markdown("##### ç›’ç‹€åœ–"); fig = go.Figure(data=[go.Box(y=col_data, name=col_name)]); fig.update_layout(xaxis_tickangle=0, template="plotly_white"); st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_num")
                else:
                    st.markdown("##### é¡åˆ¥å‹è³‡æ–™æ¬¡æ•¸åˆ†ä½ˆ"); stats_df = col_data.astype(str).value_counts().reset_index(); stats_df.columns = ['ç­”æ¡ˆé¸é …', 'æ¬¡æ•¸']; st.dataframe(stats_df)
                    st.markdown("##### å‚ç›´é•·æ¢åœ–"); fig = go.Figure(data=[go.Bar(x=stats_df['ç­”æ¡ˆé¸é …'], y=stats_df['æ¬¡æ•¸'])]); fig.update_layout(xaxis_tickangle=0, template="plotly_white"); st.plotly_chart(fig, use_container_width=True, key=f"plot_{report_title}_{i}_cat")
else:
    st.warning("æ²’æœ‰è¼‰å…¥ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆè·¯å¾‘å’Œé¸æ“‡çš„é¸é …ã€‚")
